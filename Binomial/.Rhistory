y = trainset.multinomial$diagnosis,
k = k
)
pred.model.knn <- predict(model.knn, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"], type = "class")
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset.multinomial$diagnosis)
print(confMatrix.model.knn)
var.model.knn <- varImp(model.knn, useModel = TRUE, nonpara = TRUE, scale = TRUE)
# Get only odd numbers
k <- k + 2
}
library(Biobase, lib.loc = package_loc); library(tzdb, lib.loc = package_loc); library(vroom, lib.loc = package_loc); library(readr, lib.loc = package_loc)
library(parallel)
library(doParallel)
package.install("parallel", dependencies = TRUE, lib = package_loc)
install.packages("parallel", dependencies = TRUE, lib = package_loc)
install.packages("parallel", dependencies = TRUE, lib = package_loc)
install.packages("parallel", dependencies = TRUE, lib = package_loc)
install.packages("parallel", dependencies = TRUE, lib = package_loc)
install.packages("doParallel", dependencies = TRUE, lib = package_loc)
library(parallel, lib.loc = package_loc); library(doParallel, lib.loc = package_loc)
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.multinomial.cut <- trainset.multinomial %>% group_by(diagnosis) %>% slice_sample(n = 5)
trainset.multinomial.norm <- preProcess(x = trainset.multinomial, method = c("center", "scale"))
model.nb <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trainControl(method='repeatedcv', number = 3),
preProcess = c("center", "scale"),
tuneLength = 20
)
library(Biobase, lib.loc = package_loc); library(tzdb, lib.loc = package_loc); library(vroom, lib.loc = package_loc); library(readr, lib.loc = package_loc)
library(S4Vectors, lib.loc = package_loc); library(IRanges, lib.loc = package_loc); library(XVector, lib.loc = package_loc); library(GenomeInfoDb, lib.loc = package_loc); library(Biostrings, lib.loc = package_loc)
library(backports, lib.loc = package_loc); library(Hmisc, lib.loc = package_loc); library(ggcorrplot, lib.loc = package_loc)
library(BiocGenerics, lib.loc = package_loc)
library(oligoClasses, lib.loc = package_loc); library(memoise, lib.loc = package_loc); library(pd.huex.1.0.st.v2, lib.loc = package_loc); library(oligo, lib.loc = package_loc, attach.required = TRUE)
library(caret, lib.loc = package_loc); library(locfit, lib.loc = package_loc)
library(corrr, lib.loc = package_loc); library(idm, lib.loc = package_loc); library(irlba, lib.loc = package_loc)
library(PCAtools, lib.loc = package_loc); library(RMTstat, lib.loc = package_loc); library(biomaRt, lib.loc = package_loc)
library(pROC, lib.loc = package_loc); library(withr, lib.loc = package_loc); library(caret, lib.loc = package_loc); library(dplyr, lib.loc = package_loc)
library(e1071, lib.loc = package_loc)
library(class, lib.loc = package_loc); library(gmodels, lib.loc = package_loc)
library(parallel, lib.loc = package_loc); library(doParallel, lib.loc = package_loc)
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trainControl(method='repeatedcv', number = 3),
preProcess = c("center", "scale"),
tuneLength = 20
)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trainControl(method='repeatedcv', number = 3, allowParallel = TRUE),
preProcess = c("center", "scale"),
tuneLength = 20
)
clusterEvalQ(cluster, .libPaths(cwd))
clusterEvalQ(cluster, .libPaths(package_loc))
clusterEvalQ(cluster, .libPaths(paste(datadir, "lib", sep = "")))
# Part 1.1: Sets the location of the data to be used and where the packages should be put
datadir <- "E:/jmcco/Downloads/BNF 300.2 Data/GSE208338_RAW/"
probedir <- "E:/jmcco/Downloads/BNF 300.2 Data/Affymetrix_HuEx/"
setwd(datadir)
package_loc <- paste(datadir, "lib", sep = "")
clusterEvalQ(cluster, .libPaths(package_loc))
clusterEvalQ(cluster, .libPaths("E:/jmcco/Downloads/BNF 300.2 Data/GSE208338_RAW/lib"))
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trainControl(method='repeatedcv', number = 3, allowParallel = TRUE),
preProcess = c("center", "scale"),
tuneLength = 20
)
help(registerDoParallel)
help(clusterEvalQ)
trControl.knn <- trainControl(method='repeatedcv', number = 3, allowParallel = TRUE)
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trControl.knn,
preProcess = c("center", "scale"),
tuneLength = 20
)
help(preProcess)
trainset.multinomial.preprocessed <- preProcess(trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
model.knn <- train(x = trainset.multinomial.preprocessed,
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
View(trainset.multinomial.preprocessed)
trainset.multinomial.preprocessed$knnSummary()
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
prop.table(table(trainset.multinomial$diagnosis)) * 100
help(upSample)
upSample(x = data,
y = diagnosis.fact,
yname = "diagnosis")
trainset.multinomial <- upSample(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
yname = "diagnosis")
trainset.multinomial
prop.table(table(trainset.multinomial$diagnosis)) * 100
model.nb <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "naive_bayes",
trControl = trainControl(method='cv', number=10)
)
BiocManager::install("naivebayes"),
BiocManager::install("naivebayes",
#force = TRUE,
dependencies = TRUE,
lib = package_loc
)
library(e1071, lib.loc = package_loc); library(naivebayes, lib.loc = package_loc)
model.nb <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "naive_bayes",
trControl = trainControl(method='cv', number=10)
)
pred.model.nb <- predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
confMatrix.model.nb <- confusionMatrix(pred.model.nb, testset.multinomial$diagnosis)
var.model.nb <- varImp(model.nb, useModel = TRUE, nonpara = TRUE, scale = TRUE)
trControl.knn <- trainControl(method='repeatedcv', number = 3, allowParallel = TRUE)
trainset.multinomial.preprocessed <- preProcess(trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
save.image("E:/jmcco/OneDrive - University of the Philippines/School/AY 2022-2023/2nd Sem/HI 299 Research Methods in Health Informatics/HI 299 Project/DLPFC-Gene-Expression/.RData")
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset.multinomial$diagnosis)
print(confMatrix.model.knn)
print(confMatrix.model.nb)
help(rpart)
# Part 4.3: Decision Tree
model.dt <- rpart(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
BiocManager::install(
c("rpart", "rpart.plot"),
#force = TRUE,
dependencies = TRUE,
lib = package_loc
)
library(rpart, lib.loc = package_loc); library(rpart.loc, lib.loc = package_loc)
library(rpart, lib.loc = package_loc); library(rpart.plot, lib.loc = package_loc)
# Part 4.3: Decision Tree
model.dt <- rpart(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
# Part 4.3: Decision Tree
model.dt <- rpart(formula = diagnosis ~ .
data = trainset.multinomial
# Part 4.3: Decision Tree
model.dt <- rpart(formula = diagnosis ~ .,
data = trainset.multinomial
method = "class",
# Part 4.3: Decision Tree
model.dt <- rpart(formula = diagnosis ~ .,
data = trainset.multinomial,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
help("svm")
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(diagnosis ~ .,
data = trainset.multinomial,
kernel = kernel,
cost = cost,
scale = TRUE
)
pred.model.svm <- predict(model.svm, newdata = testset.multinomial)
confMatrix.modelsvm <- confusionMatrix(pred.model.svm.testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
scale = TRUE
)
pred.model.svm <- predict(model.svm, newdata = testset.multinomial)
confMatrix.modelsvm <- confusionMatrix(pred.model.svm.testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
scale = TRUE
)
pred.model.svm <- predict(model.svm, testset.multinomial)
confMatrix.modelsvm <- confusionMatrix(pred.model.svm.testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
pred.model.svm <- predict(model.svm, testset.multinomial)
pred.model.svm <- predict(model.svm, testset.multinomial)
model.svm
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
scale = TRUE
)
pred.model.svm <- predict(model.svm, testset.multinomial)
confMatrix.modelsvm <- confusionMatrix(pred.model.svm.testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
str(trainset.multinomial) & str(testset.multinomial)
colnames(trainset.multinomial) == colnames(testset.multinomial)
levels(trainset.multinomial$diagnosis)
levels(testset.multinomial$diagnosis)
str(trainset.multinomial) & str(testset.multinomial)
str(trainset.multinomial) == str(testset.multinomial)
str(trainset.multinomial) != str(testset.multinomial)
str(trainset.multinomial) & str(testset.multinomial)
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
scale = TRUE
)
View(model.svm)
View(model.svm)
fitted(model.svm)
pred.model.svm <- predict(model.svm, testset.multinomial)
levels(trainset.multinomial) <- levels(trainset.multinomial)
levels(testset.multinomial) <- levels(testset.multinomial)
trainset.multinomial <- data.multinomial[index.multinomial, ]
testset.multinomial <- data.multinomial[-index.multinomial, ]
# Perform upsampling so that the predictors are on equal footing
trainset.multinomial <- upSample(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
yname = "diagnosis")
# Show the percentage of each predictor
prop.table(table(trainset.multinomial$diagnosis)) * 100
levels(trainset.multinomial$diagnosis) <- levels(trainset.multinomial$diagnosis)
levels(testset.multinomial$diagnosis) <- levels(testset.multinomial$diagnosis)
model.nb <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "naive_bayes",
trControl = trainControl(method='cv', number=10)
)
pred.model.nb <- predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
confMatrix.model.nb <- confusionMatrix(pred.model.nb, testset.multinomial$diagnosis)
var.model.nb <- varImp(model.nb, useModel = TRUE, nonpara = TRUE, scale = TRUE)
# Part 4.2: K Nearest Neighbors
set.seed(100)
trControl.knn <- trainControl(method='repeatedcv', number = 3, allowParallel = TRUE)
trainset.multinomial.preprocessed <- preProcess(trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
pred.model.knn <- predict(model.knn, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"], type = "class")
pred.model.knn <- predict(model.knn, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"], type = "prob")
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset.multinomial$diagnosis)
pred.model.knn <- predict(model.knn, newdata = testset.multinomial, type = "class")
pred.model.knn <- predict(model.knn, newdata = testset.multinomial, type = "prob")
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset.multinomial$diagnosis)
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset.multinomial)
pred.model.knn
levels(trainset.multinomial)
trainset.multinomial <- data.multinomial[index.multinomial, ]
testset.multinomial <- data.multinomial[-index.multinomial, ]
# Perform upsampling so that the predictors are on equal footing
trainset.multinomial <- upSample(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
yname = "diagnosis")
# Show the percentage of each predictor
prop.table(table(trainset.multinomial$diagnosis)) * 100
levels(trainset.multinomial)
# Append diagnosis.fact factors to the dataset
data.multinomial <- data
data.multinomial[, 'diagnosis'] <- diagnosis.fact
trainset.multinomial <- data.multinomial[index.multinomial, ]
testset.multinomial <- data.multinomial[-index.multinomial, ]
# Perform upsampling so that the predictors are on equal footing
trainset.multinomial <- upSample(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
yname = "diagnosis")
# Show the percentage of each predictor
prop.table(table(trainset.multinomial$diagnosis)) * 100
levels(trainset.multinomial$diagnosis) <- levels(trainset.multinomial$diagnosis)
levels(testset.multinomial$diagnosis) <- levels(testset.multinomial$diagnosis)
levels(trainset.multinomial$diagnosis)
levels(testset.multinomial$diagnosis)
testset.multinomial$diagnosis
model.nb <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "naive_bayes",
trControl = trainControl(method='cv', number=10)
)
pred.model.nb <- predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
confMatrix.model.nb <- confusionMatrix(pred.model.nb, testset.multinomial$diagnosis)
var.model.nb <- varImp(model.nb, useModel = TRUE, nonpara = TRUE, scale = TRUE)
trControl.knn <- trainControl(method='repeatedcv', number = 3, allowParallel = TRUE)
trainset.multinomial.preprocessed <- preProcess(trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
model.knn <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
pred.model.knn <- predict(model.knn, newdata = testset.multinomial)
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset.multinomial)
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset.multinomial$diagnosis)
var.model.knn <- varImp(model.knn, useModel = TRUE, nonpara = TRUE, scale = TRUE)
# Part 4.3: Decision Tree
model.dt <- rpart(formula = diagnosis ~ .,
data = trainset.multinomial,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
# Part 4.3: Decision Tree
model.dt <- rpart(formula = diagnosis ~ .,
data = as.matrix(trainset.multinomial),
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
# Part 4.3: Decision Tree
options("expressions"=20000)
memory.limit(size=8000000)
model.dt <- rpart(formula = diagnosis ~ .,
data = trainset.multinomial,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
scale = TRUE
)
pred.model.svm <- predict(model.svm, testset.multinomial)
confMatrix.modelsvm <- confusionMatrix(pred.model.svm.testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
pred.model.svm <- predict(model.svm, testset.multinomial$diagnosis)
pred.model.svm <- predict(model.svm, newdata = testset.multinomial)
ncol(model.svm)
model.svm
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
probability = TRUE,
scale = TRUE
)
pred.model.svm <- predict(model.svm, newdata = testset.multinomial)
confMatrix.modelsvm <- confusionMatrix(pred.model.svm.testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
pred.model.svm <- predict(model.svm, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
probability = TRUE,
scale = TRUE
)
pred.model.svm <- predict(model.svm, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
confMatrix.modelsvm <- confusionMatrix(pred.model.svm.testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
probability = TRUE,
scale = TRUE
)
pred.model.svm <- predict(model.svm, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
confMatrix.modelsvm <- confusionMatrix(pred.model.svm, testset.multinomial$diagnosis)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
for (kernel in c("linear", "polynomial", "radial", "sigmoid")) {
for (cost in c(0.001, 0.01, 0.1, 1, 5, 10, 100)) {
print(paste(kernel," @ ", cost))
model.svm <- svm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
kernel = kernel,
cost = cost,
probability = TRUE,
scale = TRUE
)
pred.model.svm <- predict(model.svm, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"])
confMatrix.modelsvm <- confusionMatrix(pred.model.svm, testset.multinomial$diagnosis)
print(confMatrix.modelsvm)
#err_metric(confMatrix.modelsvm$table[1,1], confMatrix.modelsvm$table[2,2], confMatrix.modelsvm$table[1,2], confMatrix.modelsvm$table[2,1])
# modelsvm <- cbind(modelsvm, c(modelsvm))
}
}
model.nb <- train(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
y = trainset.multinomial$diagnosis,
method = "multinomial_naive_bayes",
trControl = trainControl(method='cv', number=10)
)
BiocManager::install(
c(
"multinom"),
#force = TRUE,
dependencies = TRUE,
lib = package_loc
)
library(multinom, lib.loc = package_loc)
install.packages(c("multinom"), dependencies = TRUE, lib = package_loc)
library(nnet, lib.loc = package_loc)
help("multinom")
# Part 4.5: Logistic Regression
#model.logit <- glm(x = trainset.multinomial[, colnames(trainset.multinomial) != "diagnosis"],
#                   y = trainset.multinomial$diagnosis,
#                   family = binomial(link = "logit"),
#               )
model.logit <- multinom(diagnosis ~ .,
data = trainset.multinomial)
hepl(randomForest)
help(randomForest)
BiocManager::install(
c("randomForest"),
#force = TRUE,
dependencies = TRUE,
lib = package_loc
)
library(randomForest, lib.loc = package_loc)
# Part 4.6: Discriminant Analysis
# Part 4.7: Random Forest
model.rf <- randomForest(diagnosis ~ .,
data = trainset.multinomial,
ntree = 300,
mtry = 21591
)
library(psych, lib = package_loc)
