}
# Part 4.3.3.2.4: SVM
learn.features.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'laplacedot', svm.cost = 0.1)
# Part 4.3.3.1: Perform tuning for SVM and Random Forest
perform_learning("SVM", trainset.multinomial, testset.multinomial, tune = TRUE)
# Part 4.2: Create a function for each ML
perform_learning <- function(method, trainset, testset,
svm.kernel = NULL,
svm.cost = NULL,
rf.ntree = NULL,
rf.mtry = NULL,
export.filename = NULL,
tune = FALSE) {
if (method == "NB") {
# Part 4.1: Naive Bayes
set.seed(100)
model.nb <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "naive_bayes",
trControl = trainControl(method='cv', number=10)
)
pred.model.nb <- predict(model.nb, newdata = testset[, colnames(trainset) != "diagnosis"])
roc.model.nb <- multiclass.roc(response = testset$diagnosis,
predictor = predict(model.nb,
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob"),
percent = TRUE)
confMatrix.model.nb <- confusionMatrix(pred.model.nb, testset$diagnosis)
var.model.nb <- varImp(model.nb, useModel = TRUE, nonpara = TRUE, scale = TRUE)
return(list(model = model.nb, pred = pred.model.nb, confMatrix = confMatrix.model.nb, var = var.model.nb, roc = roc.model.nb))
} else if (method == "KNN") {
# Part 4.2: K Nearest Neighbors
set.seed(100)
trControl.knn <- trainControl(method='repeatedcv', number = 3, allowParallel = TRUE)
trainset.preprocessed <- preProcess(trainset[, colnames(trainset) != "diagnosis"])
model.knn <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
pred.model.knn <- predict(model.knn, newdata = testset)
roc.model.knn <- multiclass.roc(response = testset$diagnosis,
predictor = predict(model.knn,
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob"),
percent = TRUE)
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset$diagnosis)
var.model.knn <- varImp(model.knn, useModel = TRUE, nonpara = TRUE, scale = TRUE)
return(list(model = model.knn, pred = pred.model.knn, confMatrix = confMatrix.model.knn, var = var.model.knn, roc = roc.model.knn))
} else if (method == "DT") {
# Part 4.3: Decision Tree
# Part 4.3.1: Using rpart
model.dt <- rpart(formula = diagnosis ~ .,
data = trainset,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
var.model.dt<- varImp(model.dt, useModel = TRUE, nonpara = TRUE, scale = TRUE)
arrange(var.model.dt, desc(Overall))
rpart.plot(model.dt)
pdf(export.filename)
prp(model.dt, extra=104)
dev.off()
# Part 4.3.2: Using train
## 10-fold CV
## repeated ten times
trControl.dt <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 10)
model.dt <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "rpart2",
trControl = trControl.dt
)
pred.model.dt <- predict(model.dt, newdata = testset)
roc.model.dt <- multiclass.roc(response = testset$diagnosis,
predictor = predict(model.dt,
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob"),
percent = TRUE)
confMatrix.model.dt <- confusionMatrix(pred.model.dt, testset$diagnosis)
return(list(model = model.dt, pred = pred.model.dt, confMatrix = confMatrix.model.dt, var = var.model.dt, roc = roc.model.dt))
} else if (method == "SVM") {
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
if (tune) {
kernels <- c("rbfdot", "polydot", "tanhdot", "vanilladot", "laplacedot", "besseldot", "anovadot", "splinedot")
costs <- c(0.001, 0.01, 0.1, 1, 5, 10, 100)
} else {
kernels <- c(svm.kernel)
costs <- c(svm.cost)
}
for (kernel in kernels) {
for (cost in costs) {
model.svm <- rminer::fit(diagnosis ~ .,
data = trainset,
model = "svm",
kernel = kernel,
kpar = "automatic",
C = cost,
task = "class"
)
pred.model.svm <- predict(model.svm, newdata = testset)
confMatrix.model.svm <- confusionMatrix(pred.model.svm, testset$diagnosis)
var.model.svm <- Importance(model.svm, data = trainset)
#if (!tune) {
roc.model.svm <- multiclass.roc(response = testset$diagnosis,
predictor = predict(rminer::fit(diagnosis ~ .,
data = trainset,
model = "svm",
kernel = kernel,
kpar = "automatic",
C = cost
),
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob"),
percent = TRUE)
#}
#if (tune && confMatrix.model.svm$overall['AccuracyPValue'] < 0.05) {
if (tune) {
print(paste(kernel," @ ", cost))
print(confMatrix.model.svm$overall['Accuracy'])
print(confMatrix.model.svm$overall['AccuracyPValue'])
print(roc.model.svm$auc)
}
}
}
if (!tune) {
return(list(model = model.svm, pred = pred.model.svm, confMatrix = confMatrix.model.svm, var = var.model.svm, roc = roc.model.svm))
}
} else if (method == "LOG") {
model.logit <- multinom(diagnosis ~ .,
data = trainset)
pred.model.logit <- predict(model.logit, newdata = testset[, colnames(testset) != "diagnosis"], type = "class")
roc.model.logit <- multiclass.roc(response = testset$diagnosis,
predictor = predict(model.logit,
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob"),
percent = TRUE)
confMatrix.model.logit <- confusionMatrix(pred.model.logit, testset$diagnosis)
var.model.logit <- varImp(model.logit, useModel = TRUE, nonpara = TRUE, scale = TRUE)
#summary(model.logit)
#View(cbind("coeff" = coef(model.logit), "odds ratio" = (exp(coef(model.logit)) - 1) * 100)) # Odds ratio
return(list(model = model.logit, pred = pred.model.logit, confMatrix = confMatrix.model.logit, var = var.model.logit, roc = roc.model.logit))
} else if (method == "DA") {
# Part 4.6: Discriminant Analysis
trControl.lda <- trainControl(classProbs = TRUE)
levels(trainset$diagnosis)[match("1",levels(trainset$diagnosis))] <- "BPD"
levels(trainset$diagnosis)[match("2",levels(trainset$diagnosis))] <- "MDD"
levels(trainset$diagnosis)[match("3",levels(trainset$diagnosis))] <- "SCZ"
levels(trainset$diagnosis)[match("9",levels(trainset$diagnosis))] <- "CTL"
model.lda <- train(diagnosis ~ .,
data = trainset,
method = "lda",
trControl = trControl.lda)
levels(testset$diagnosis)[match("1",levels(testset$diagnosis))] <- "BPD"
levels(testset$diagnosis)[match("2",levels(testset$diagnosis))] <- "MDD"
levels(testset$diagnosis)[match("3",levels(testset$diagnosis))] <- "SCZ"
levels(testset$diagnosis)[match("9",levels(testset$diagnosis))] <- "CTL"
var.model.lda <- varImp(model.lda, useModel = TRUE, nonpara = TRUE, scale = TRUE)
model.lda <- lda(diagnosis ~ .,
data = trainset,
)
pred.model.lda <- predict(model.lda, newdata = testset)
roc.model.lda <- multiclass.roc(response = testset$diagnosis,
predictor = predict(model.lda,
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob")$posterior,
percent = TRUE)
confMatrix.model.lda <- confusionMatrix(pred.model.lda$class, testset$diagnosis)
#return(list(model = model.lda, pred = pred.model.lda, confMatrix = confMatrix.model.lda, var = var.model.lda))
return(list(model = model.lda, pred = pred.model.lda, confMatrix = confMatrix.model.lda, var = var.model.lda, roc = roc.model.lda))
} else if (method == "RF") {
# Part 4.7: Random Forest
set.seed(100)
if (tune) {
mtries <- sort.int(sample(ncol(trainset)-1, 5))
ntrees <- c(201, 501, 1501, 2501, 3501)
} else {
mtries <- c(rf.mtry)
ntrees <- c(rf.ntree)
}
for(ntree in ntrees) {
for(mtry in mtries) {
model.rf <- randomForest(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
ntree = ntree,
mtry = mtry
)
pred.model.rf <- predict(model.rf, newdata = testset)
#if (!tune) {
roc.model.rf <- multiclass.roc(response = testset$diagnosis,
predictor = predict(model.rf,
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob"),
percent = TRUE)
#}
confMatrix.model.rf <- confusionMatrix(pred.model.rf, testset$diagnosis)
#if (tune && confMatrix.model.rf$overall['AccuracyPValue'] < 0.05) {
if (tune) {
print(paste(ntree," and ", mtry))
print(confMatrix.model.rf$overall['Accuracy'])
print(confMatrix.model.rf$overall['AccuracyPValue'])
print(roc.model.rf$auc)
}
var.model.rf <- varImp(model.rf, useModel = TRUE, nonpara = TRUE, scale = TRUE)
var.model.rf <- arrange(var.model.rf, desc(Overall))
}
}
if (!tune) {
return(list(model = model.rf, pred = pred.model.rf, confMatrix = confMatrix.model.rf, var = var.model.rf, roc = roc.model.rf))
}
} else {
model.auto <- rminer::fit(diagnosis ~ .,
data = trainset,
model = "auto",
fdebug = TRUE,
search = list(
search = mparheuristic(
model = c("naive","ctree","cv.glmnet","rpart","kknn","ksvm","lssvm","mlp","mlpe", "randomForest","lda","multinom", "naiveBayes","xgboost"),
task = "class",
inputs = ncol(trainset)-1
),
smethod = "auto",
metric = "AUC",
convex = 0
)
)
pred.model.auto <- predict(model.auto, testset)
roc.model.auto <- multiclass.roc(response = testset$diagnosis,
predictor = predict(model.auto,
newdata = testset[, colnames(testset) != "diagnosis"],
type = "prob"),
percent = TRUE)
var.model.auto <- Importance(model.auto, data = trainset, method = "DSA")
# show leaderboard:
cat("Models  by rank:", model.auto@mpar$LB$model, "\n")
cat("Validation values:", round(model.auto@mpar$LB$eval,4), "\n")
cat("Best model:", model.auto@model, "\n")
cat("AUC", "=", round(mmetric(testset$diagnosis, pred.model.auto, metric="AUC"),2), "\n")
return(list(model = model.auto, pred = pred.model.auto, confMatrix = c(), var = var.model.auto, roc = roc.model.auto))
}
}
# Part 4.3.3.2.4: SVM
learn.features.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'laplacedot', svm.cost = 0.1)
perform_learning("RF", trainset.multinomial, testset.multinomial, tune = TRUE)
# Part 4.3.3: Combined Dataset
data.multinomial <- createDataset(dataSource = data.pp, feature = features, probeset = huex.probes, filename = "PCA + GF")
sets <- buildTrainTest(data.multinomial)
trainset.multinomial <- sets$trainset
testset.multinomial <- sets$testset
remove(sets)
perform_learning("RF", trainset.multinomial, testset.multinomial, tune = TRUE)
# Part 5 - Ranking
exportsubdir <- "Step 5 - Ranking"
dir.create(paste(exportdir, exportsubdir, sep = "/"), recursive=TRUE)
# Part 5.1. Build list
ranking <- list(
naive_bayes.gf = rownames(learn.gf.nb$var$importance)[1:20],
naive_bayes.pca = rownames(learn.pca.nb$var$importance)[1:20],
naive_bayes.features = rownames(learn.features.nb$var$importance)[1:20],
knn.gf = rownames(learn.gf.knn$var$importance)[1:20],
knn.pca = rownames(learn.pca.knn$var$importance)[1:20],
knn.features = rownames(learn.features.knn$var$importance)[1:20],
svm.gf = rownames(learn.gf.svm$var$importance)[1:20],
svm.pca = rownames(learn.pca.svm$var$importance)[1:20],
svm.features = rownames(learn.features.svm$var$importance)[1:20],
logistic_regression.gf = gsub("`", "", rownames(learn.gf.log$var), fixed = T)[1:20],
logistic_regression.pca = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
logistic_regression.features = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
discriminant_analysis.gf = rownames(learn.gf.da$var$importance)[1:20],
discriminant_analysis.pca = rownames(learn.pca.da$var$importance)[1:20],
discriminant_analysis.features = rownames(learn.features.da$var$importance)[1:20],
decision_tree.gf = rownames(learn.gf.dt$var)[1:20],
decision_tree.pca = rownames(learn.pca.dt$var)[1:20],
decision_tree.features = rownames(learn.features.dt$var)[1:20],
random_forest.gf = rownames(learn.gf.rf$var)[1:20],
random_forest.pca = rownames(learn.pca.rf$var)[1:20],
random_forest.features = rownames(learn.features.rf$var)[1:20]
)
# Step 5.2: Export
write.csv(ranking, paste(exportdir, exportsubdir, "Ranking.csv", sep = "/"), row.names = TRUE)
rownames(learn.pca.rf$var)[1:20]
rownames(learn.pca.svm$var$importance)[1:20]
# Part 4.3.2.2.4: SVM (For PCA, SVM tuning had no significant features)
learn.pca.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'rbfdot', svm.cost = 1)
# Part 5 - Ranking
exportsubdir <- "Step 5 - Ranking"
dir.create(paste(exportdir, exportsubdir, sep = "/"), recursive=TRUE)
# Part 5.1. Build list
ranking <- list(
naive_bayes.gf = rownames(learn.gf.nb$var$importance)[1:20],
naive_bayes.pca = rownames(learn.pca.nb$var$importance)[1:20],
naive_bayes.features = rownames(learn.features.nb$var$importance)[1:20],
knn.gf = rownames(learn.gf.knn$var$importance)[1:20],
knn.pca = rownames(learn.pca.knn$var$importance)[1:20],
knn.features = rownames(learn.features.knn$var$importance)[1:20],
svm.gf = rownames(learn.gf.svm$var$importance)[1:20],
svm.pca = rownames(learn.pca.svm$var$importance)[1:20],
svm.features = rownames(learn.features.svm$var$importance)[1:20],
logistic_regression.gf = gsub("`", "", rownames(learn.gf.log$var), fixed = T)[1:20],
logistic_regression.pca = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
logistic_regression.features = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
discriminant_analysis.gf = rownames(learn.gf.da$var$importance)[1:20],
discriminant_analysis.pca = rownames(learn.pca.da$var$importance)[1:20],
discriminant_analysis.features = rownames(learn.features.da$var$importance)[1:20],
decision_tree.gf = rownames(learn.gf.dt$var)[1:20],
decision_tree.pca = rownames(learn.pca.dt$var)[1:20],
decision_tree.features = rownames(learn.features.dt$var)[1:20],
random_forest.gf = rownames(learn.gf.rf$var)[1:20],
random_forest.pca = rownames(learn.pca.rf$var)[1:20],
random_forest.features = rownames(learn.features.rf$var)[1:20]
)
# Step 5.2: Export
write.csv(ranking, paste(exportdir, exportsubdir, "Ranking.csv", sep = "/"), row.names = TRUE)
rownames(learn.pca.svm$var$importance)[1:20]
learn.pca.svm$var
source_url('https://gist.githubusercontent.com/fawda123/6206737/raw/d6f365c283a8cae23fb20892dc223bc5764d50c7/gar_fun.r')
library("downloader")
install.packages("downloader", lib.loc = package_loc)
install.packages("downloader", lib = package_loc)
library("downloader", lib.loc = package_loc)
source_url('https://gist.githubusercontent.com/fawda123/6206737/raw/d6f365c283a8cae23fb20892dc223bc5764d50c7/gar_fun.r')
nrow(features)
nrows(features)
length(features)
#create a pretty color vector for the bar plot
cols<-colorRampPalette(c('lightgreen','lightblue'))(length(features))
#use the function on the model created above
par(mar=c(3,4,1,1),family='serif')
gar.fun('diagnosis', learn.features.svm$model, col=cols, ylab='Rel. importance',ylim=c(-1,1))
gar.fun('diagnosis', learn.features.svm$model)
install.packages(c("downloader", "scales", "reshape"), lib = package_loc)
install.packages(c("downloader", "scales", "reshape"), lib = package_loc)
library("downloader", lib.loc = package_loc); library("scales", lib.loc = package_loc); library("reshape", lib.loc = package_loc)
gar.fun('diagnosis', learn.features.svm$model)
learn.features.svm$var$inputs
learn.features.svm$var$imp
learn.features.svm$var$sresponses
learn.features.svm$var$nclasses
learn.features.svm$var$data
learn.features.svm$var$value
learn.features.svm$var$imp
learn.features.svm$var$interactions
learn.features.svm$var$Llevels
learn.features.svm$var$sresponses
learn.features.svm$var$sresponses[[1:50]]$n
learn.features.svm$var$sresponses[[1]]$n
learn.features.svm$var$sresponses[[2]]$n
learn.features.svm$var$sresponses[[3]]$n
for(i in 1:length(features)) {
print(learn.features.svm$var$sresponses[[i]]$n)
}
features
c(features, learn.features.svm$var$imp)
data.frame(' ' = features, "Overall" = learn.features.svm$var$imp)
data.frame(' ' = features, "Overall" = learn.features.svm$var$imp[-1])
learn.features.svm$var <- data.frame(' ' = features, "Overall" = learn.features.svm$var$imp)
learn.features.svm$var <- data.frame(' ' = features, "Overall" = learn.features.svm$var$imp[-1])
learn.features.svm$var[order(-learn.features.svm$var), ]
order(-learn.features.svm$var)
order(learn.features.svm$var)
order(-learn.features.svm$var$Overall)
learn.features.svm$var <- data.frame(' ' = features, "Overall" = learn.features.svm$var$imp[-1])
learn.features.svm$var[order(-learn.features.svm$var$Overall), ]
learn.features.svm$var <- learn.features.svm$var[order(-learn.features.svm$var$Overall), ]
learn.gf.svm$var <- data.frame(' ' = features, "Overall" = learn.gf.svm$var$imp[-1])
learn.gf.svm$var <- learn.features.svm$var[order(-learn.gf.svm$var$Overall), ]
learn.gf.svm$var <- data.frame(' ' = features.gf, "Overall" = learn.gf.svm$var$imp[-1])
learn.gf.svm$var <- learn.features.svm$var[order(-learn.gf.svm$var$Overall), ]
learn.pca.svm$var <- data.frame(' ' = features.pca, "Overall" = learn.pca.svm$var$imp[-1])
# Part 4.3.2: PCA Dataset
data.multinomial <- createDataset(dataSource = data.pp, feature = features.pca, probeset = huex.probes, filename = "PCA")
sets <- buildTrainTest(data.multinomial)
trainset.multinomial <- sets$trainset
testset.multinomial <- sets$testset
remove(sets)
# Part 4.3.2.2.4: SVM (For PCA, SVM tuning had no significant features)
learn.pca.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'rbfdot', svm.cost = 1)
learn.pca.svm$var <- data.frame(' ' = features.pca, "Overall" = learn.pca.svm$var$imp[-1])
learn.pca.svm$var <- learn.features.svm$var[order(-learn.pca.svm$var$Overall), ]
# Part 4.3: Perform ML
# Part 4.3.1: Gene Filtering Dataset
data.multinomial <- createDataset(dataSource = data.pp, feature = features.gf, probeset = huex.probes, filename = "Gene Filtering")
sets <- buildTrainTest(data.multinomial)
trainset.multinomial <- sets$trainset
testset.multinomial <- sets$testset
remove(sets)
# Part 4.3.1.2.4: SVM
learn.gf.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'laplacedot', svm.cost = 100)
learn.gf.svm$var <- data.frame('feature' = features.gf, "Overall" = learn.gf.svm$var$imp[-1])
learn.gf.svm$var <- learn.features.svm$var[order(-learn.gf.svm$var$Overall), ]
# Part 4.3.2: PCA Dataset
data.multinomial <- createDataset(dataSource = data.pp, feature = features.pca, probeset = huex.probes, filename = "PCA")
sets <- buildTrainTest(data.multinomial)
trainset.multinomial <- sets$trainset
testset.multinomial <- sets$testset
remove(sets)
# Part 4.3.2.2.4: SVM (For PCA, SVM tuning had no significant features)
learn.pca.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'rbfdot', svm.cost = 1)
learn.pca.svm$var <- data.frame('feature' = features.pca, "Overall" = learn.pca.svm$var$imp[-1])
learn.pca.svm$var <- learn.features.svm$var[order(-learn.pca.svm$var$Overall), ]
# Part 4.3.3: Combined Dataset
data.multinomial <- createDataset(dataSource = data.pp, feature = features, probeset = huex.probes, filename = "PCA + GF")
sets <- buildTrainTest(data.multinomial)
trainset.multinomial <- sets$trainset
testset.multinomial <- sets$testset
remove(sets)
# Part 4.3.3.2.4: SVM
learn.features.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'laplacedot', svm.cost = 0.1)
learn.features.svm$var <- data.frame('feature' = features, "Overall" = learn.features.svm$var$imp[-1])
learn.features.svm$var <- learn.features.svm$var[order(-learn.features.svm$var$Overall), ]
# Part 5 - Ranking
exportsubdir <- "Step 5 - Ranking"
dir.create(paste(exportdir, exportsubdir, sep = "/"), recursive=TRUE)
# Part 5.1. Build list
ranking <- list(
naive_bayes.gf = rownames(learn.gf.nb$var$importance)[1:20],
naive_bayes.pca = rownames(learn.pca.nb$var$importance)[1:20],
naive_bayes.features = rownames(learn.features.nb$var$importance)[1:20],
knn.gf = rownames(learn.gf.knn$var$importance)[1:20],
knn.pca = rownames(learn.pca.knn$var$importance)[1:20],
knn.features = rownames(learn.features.knn$var$importance)[1:20],
svm.gf = rownames(learn.gf.svm$var$feature)[1:20],
svm.pca = rownames(learn.pca.svm$var$feature)[1:20],
svm.features = rownames(learn.features.svm$var$feature)[1:20],
logistic_regression.gf = gsub("`", "", rownames(learn.gf.log$var), fixed = T)[1:20],
logistic_regression.pca = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
logistic_regression.features = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
discriminant_analysis.gf = rownames(learn.gf.da$var$importance)[1:20],
discriminant_analysis.pca = rownames(learn.pca.da$var$importance)[1:20],
discriminant_analysis.features = rownames(learn.features.da$var$importance)[1:20],
decision_tree.gf = rownames(learn.gf.dt$var)[1:20],
decision_tree.pca = rownames(learn.pca.dt$var)[1:20],
decision_tree.features = rownames(learn.features.dt$var)[1:20],
random_forest.gf = rownames(learn.gf.rf$var)[1:20],
random_forest.pca = rownames(learn.pca.rf$var)[1:20],
random_forest.features = rownames(learn.features.rf$var)[1:20]
)
# Step 5.2: Export
write.csv(ranking, paste(exportdir, exportsubdir, "Ranking.csv", sep = "/"), row.names = TRUE)
rownames(learn.gf.svm$var$feature)
learn.gf.svm$var$feature
# Part 4.3.3.2.4: SVM
learn.features.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'laplacedot', svm.cost = 0.1)
learn.features.svm$var <- data.frame('feature' = features, "Overall" = learn.features.svm$var$imp[-1])
learn.features.svm$var
learn.features.svm$var$feature
learn.gf.svm$var$feature[1:20]
learn.gpca.svm$var$feature[1:20]
learn.pca.svm$var$feature[1:20]
learn.feature.svm$var$feature[1:20]
learn.features.svm$var$feature[1:20]
# Part 4.3: Perform ML
# Part 4.3.1: Gene Filtering Dataset
data.multinomial <- createDataset(dataSource = data.pp, feature = features.gf, probeset = huex.probes, filename = "Gene Filtering")
sets <- buildTrainTest(data.multinomial)
trainset.multinomial <- sets$trainset
testset.multinomial <- sets$testset
remove(sets)
# Part 4.3.1.2.4: SVM
learn.gf.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'laplacedot', svm.cost = 100)
learn.gf.svm$var <- data.frame('feature' = features.gf, "Overall" = learn.gf.svm$var$imp[-1])
learn.gf.svm$var <- learn.gf.svm$var[order(-learn.gf.svm$var$Overall), ]
# Part 4.3.2: PCA Dataset
data.multinomial <- createDataset(dataSource = data.pp, feature = features.pca, probeset = huex.probes, filename = "PCA")
sets <- buildTrainTest(data.multinomial)
trainset.multinomial <- sets$trainset
testset.multinomial <- sets$testset
remove(sets)
# Part 4.3.2.2.4: SVM (For PCA, SVM tuning had no significant features)
learn.pca.svm <- perform_learning("SVM", trainset.multinomial, testset.multinomial, svm.kernel = 'rbfdot', svm.cost = 1)
learn.pca.svm$var <- data.frame('feature' = features.pca, "Overall" = learn.pca.svm$var$imp[-1])
learn.pca.svm$var <- learn.pca.svm$var[order(-learn.pca.svm$var$Overall), ]
# Part 5 - Ranking
exportsubdir <- "Step 5 - Ranking"
dir.create(paste(exportdir, exportsubdir, sep = "/"), recursive=TRUE)
# Part 5.1. Build list
ranking <- list(
naive_bayes.gf = rownames(learn.gf.nb$var$importance)[1:20],
naive_bayes.pca = rownames(learn.pca.nb$var$importance)[1:20],
naive_bayes.features = rownames(learn.features.nb$var$importance)[1:20],
knn.gf = rownames(learn.gf.knn$var$importance)[1:20],
knn.pca = rownames(learn.pca.knn$var$importance)[1:20],
knn.features = rownames(learn.features.knn$var$importance)[1:20],
svm.gf = learn.gf.svm$var$feature[1:20],
svm.pca =learn.pca.svm$var$feature[1:20],
svm.features = learn.features.svm$var$feature[1:20],
logistic_regression.gf = gsub("`", "", rownames(learn.gf.log$var), fixed = T)[1:20],
logistic_regression.pca = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
logistic_regression.features = gsub("`", "", rownames(learn.pca.log$var), fixed = T)[1:20],
discriminant_analysis.gf = rownames(learn.gf.da$var$importance)[1:20],
discriminant_analysis.pca = rownames(learn.pca.da$var$importance)[1:20],
discriminant_analysis.features = rownames(learn.features.da$var$importance)[1:20],
decision_tree.gf = rownames(learn.gf.dt$var)[1:20],
decision_tree.pca = rownames(learn.pca.dt$var)[1:20],
decision_tree.features = rownames(learn.features.dt$var)[1:20],
random_forest.gf = rownames(learn.gf.rf$var)[1:20],
random_forest.pca = rownames(learn.pca.rf$var)[1:20],
random_forest.features = rownames(learn.features.rf$var)[1:20]
)
# Step 5.2: Export
write.csv(ranking, paste(exportdir, exportsubdir, "Ranking.csv", sep = "/"), row.names = TRUE)
# Step 5.3: Get data from annotation
write.csv(huex.probes[, which(huex.probes$probeset_id %in% features)], paste(exportdir, exportsubdir, "Annotated Features.csv", sep = "/"), row.names = TRUE)
save.image("E:/jmcco/OneDrive - University of the Philippines/School/AY 2022-2023/2nd Sem/HI 299 Research Methods in Health Informatics/HI 299 Project/DLPFC-Gene-Expression/Multinomial/.RData")
# Step 5.3: Get data from annotation
write.csv(huex.probes[, which(huex.probes$probeset_id %in% features)], paste(exportdir, exportsubdir, "Annotated Features.csv", sep = "/"), row.names = TRUE)
