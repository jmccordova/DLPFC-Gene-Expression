# show leaderboard:
cat("Models  by rank:", model.auto@mpar$LB$model, "\n")
cat("Validation values:", round(model.auto@mpar$LB$eval,4), "\n")
cat("Best model:", model.auto@model, "\n")
cat("AUC", "=", round(mmetric(testset$diagnosis, pred.model.auto, metric="AUC"),2), "\n")
return(list(model = model.auto, pred = pred.model.auto, confMatrix = c(), var = var.model.auto))
}
}
# Part 4.3.1.2.6: Discriminant Analysis
learn.gf.da <- perform_learning("DA", trainset.multinomial[, features.selected], testset.multinomial[, features.selected])
# Part 4.2: Create a function for each ML
perform_learning <- function(method, trainset, testset,
svm.kernel = NULL,
svm.cost = NULL,
rf.ntree = NULL,
rf.mtry = NULL,
export.filename = NULL,
tune = FALSE) {
if (method == "NB") {
# Part 4.1: Naive Bayes
set.seed(100)
model.nb <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "naive_bayes",
trControl = trainControl(method='cv', number=10)
)
pred.model.nb <- predict(model.nb, newdata = testset[, colnames(trainset) != "diagnosis"])
confMatrix.model.nb <- confusionMatrix(pred.model.nb, testset$diagnosis)
var.model.nb <- varImp(model.nb, useModel = TRUE, nonpara = TRUE, scale = TRUE)
return(list(model = model.nb, pred = pred.model.nb, confMatrix = confMatrix.model.nb, var = var.model.nb))
} else if (method == "KNN") {
# Part 4.2: K Nearest Neighbors
set.seed(100)
trControl.knn <- trainControl(method='repeatedcv', number = 3, allowParallel = TRUE)
trainset.preprocessed <- preProcess(trainset[, colnames(trainset) != "diagnosis"])
model.knn <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
pred.model.knn <- predict(model.knn, newdata = testset)
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset$diagnosis)
var.model.knn <- varImp(model.knn, useModel = TRUE, nonpara = TRUE, scale = TRUE)
return(list(model = model.knn, pred = pred.model.knn, confMatrix = confMatrix.model.knn, var = var.model.knn))
} else if (method == "DT") {
# Part 4.3: Decision Tree
# Part 4.3.1: Using rpart
model.dt <- rpart(formula = diagnosis ~ .,
data = trainset,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
var.model.dt<- varImp(model.dt, useModel = TRUE, nonpara = TRUE, scale = TRUE)
rpart.plot(model.dt)
pdf(export.filename)
prp(model.dt, extra=104)
dev.off()
# Part 4.3.2: Using train
## 10-fold CV
## repeated ten times
trControl.dt <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 10)
model.dt <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "rpart2",
trControl = trControl.dt
)
pred.model.dt <- predict(model.dt, newdata = testset)
confMatrix.model.dt <- confusionMatrix(pred.model.dt, testset$diagnosis)
return(list(model = model.dt, pred = pred.model.dt, confMatrix = confMatrix.model.dt, var = var.model.dt))
} else if (method == "SVM") {
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
if (tune) {
kernels <- c("rbfdot", "polydot", "tanhdot", "vanilladot", "laplacedot", "besseldot", "anovadot", "splinedot")
costs <- c(0.001, 0.01, 0.1, 1, 5, 10, 100)
} else {
kernels <- c(svm.kernel)
costs <- c(svm.cost)
}
for (kernel in kernels) {
for (cost in costs) {
model.svm <- rminer::fit(diagnosis ~ .,
data = trainset,
model = "svm",
kernel = kernel,
kpar = "automatic",
C = cost,
task = "class"
)
pred.model.svm <- predict(model.svm, newdata = testset)
confMatrix.model.svm <- confusionMatrix(pred.model.svm, testset$diagnosis)
if (tune && confMatrix.model.svm$overall['AccuracyPValue'] < 0.05) {
print(paste(kernel," @ ", cost))
print(confMatrix.model.svm)
}
var.model.svm <- Importance(model.svm, data = trainset)
}
}
if (!tune) {
return(list(model = model.nb, pred = pred.model.nb, confMatrix = confMatrix.model.nb, var = var.model.nb))
}
} else if (method == "LOG") {
model.logit <- multinom(diagnosis ~ .,
data = trainset)
pred.model.logit <- predict(model.logit, newdata = testset[, colnames(testset) != "diagnosis"], type = "class")
confMatrix.model.logit <- confusionMatrix(pred.model.logit, testset$diagnosis)
var.model.logit <- varImp(model.logit, useModel = TRUE, nonpara = TRUE, scale = TRUE)
summary(model.logit)
View(cbind("coeff" = coef(model.logit), "odds ratio" = (exp(coef(model.logit)) - 1) * 100)) # Odds ratio
return(list(model = model.logit, pred = pred.model.logit, confMatrix = confMatrix.model.logit, var = var.model.logit))
} else if (method == "DA") {
# Part 4.6: Discriminant Analysis
model.lda <- lda(diagnosis ~ .,
data = trainset,
)
pred.model.lda <- predict(model.lda, newdata = testset)
confMatrix.model.lda <- confusionMatrix(pred.model.lda$class, testset$diagnosis)
#var.model.lda <- varImp(model.lda, useModel = TRUE, nonpara = TRUE, scale = TRUE)
#return(list(model = model.lda, pred = pred.model.lda, confMatrix = confMatrix.model.lda, var = var.model.lda))
return(list(model = model.lda, pred = pred.model.lda, confMatrix = confMatrix.model.lda))
} else if (method == "RF") {
# Part 4.7: Random Forest
set.seed(100)
if (tune) {
mtries <- sort.int(sample(ncol(trainset)-1, 5))
ntrees <- c(201, 501, 1501, 2501, 3501)
} else {
mtries <- c(rf.mtry)
ntrees <- c(rf.ntree)
}
for(ntree in ntrees) {
for(mtry in mtries) {
model.rf <- randomForest(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
ntree = ntree,
mtry = mtry
)
pred.model.rf <- predict(model.rf, newdata = testset)
confMatrix.model.rf <- confusionMatrix(pred.model.rf, testset$diagnosis)
if (tune && confMatrix.model.rf$overall['AccuracyPValue'] < 0.05) {
print(paste(ntree," and ", mtry))
print(confMatrix.model.rf)
}
var.model.rf <- varImp(model.rf, useModel = TRUE, nonpara = TRUE, scale = TRUE)
}
}
if (!tune) {
return(list(model = model.rf, pred = pred.model.rf, confMatrix = confMatrix.model.rf, var = var.model.rf))
}
} else {
model.auto <- rminer::fit(diagnosis ~ .,
data = trainset,
model = "auto",
fdebug = TRUE,
search = list(
search = mparheuristic(
model = c("naive","ctree","cv.glmnet","rpart","kknn","ksvm","lssvm","mlp","mlpe", "randomForest","lda","multinom", "naiveBayes","xgboost"),
task = "class",
inputs = ncol(trainset)-1
),
smethod = "auto",
metric = "AUC",
convex = 0
)
)
pred.model.auto <- predict(model.auto, testset)
var.model.auto <- Importance(model.auto, data = trainset, method = "DSA")
# show leaderboard:
cat("Models  by rank:", model.auto@mpar$LB$model, "\n")
cat("Validation values:", round(model.auto@mpar$LB$eval,4), "\n")
cat("Best model:", model.auto@model, "\n")
cat("AUC", "=", round(mmetric(testset$diagnosis, pred.model.auto, metric="AUC"),2), "\n")
return(list(model = model.auto, pred = pred.model.auto, confMatrix = c(), var = var.model.auto))
}
}
# Part 4.3.1.2.6: Discriminant Analysis
learn.gf.da <- perform_learning("DA", trainset.multinomial[, features.selected], testset.multinomial[, features.selected])
# Part 4.3.1.2.7: Decision Tree
learn.gf.dt <- perform_learning("DT", trainset.multinomial[, features.selected], testset.multinomial[, features.selected], export.filename = paste(datadir, "../Export/Decision Tree (Gene Filter).pdf", sep = ""))
# Part 4.3.1.2.8: Random Forest
learn.gf.rf <- perform_learning("RF", trainset.multinomial[, features.selected], testset.multinomial[, features.selected], rf.ntree = 201, rf.mtry = 10)
learn.gf.dt
learn.gf.rf
# Part 4.3.2: PCA Dataset
features.selected <- c(features.pca, "diagnosis")
# Part 4.3.2.1: Perform tuning for SVM and Random Forest
perform_learning("SVM", trainset.multinomial[, features.selected], testset.multinomial[, features.selected], tune = TRUE)
trainset.multinomial[, features.selected]
features.selected
colnames(trainset.multinomial)
features.selected %ni% colnames(trainset.multinomial)
features.selected[features.selected %ni% colnames(trainset.multinomial)]
data.multinomial[, features.selected]
data.multinomial[features.selected, ]
rownames(data.multinomial)
colnames(data.multinomial)
features
# Part 3.4.1: Get only the chosen features
data.multinomial <- as.matrix(exprs(data.pp)[features, ])
# Part 3.4.2: Replace the features into their transcript ID
# Part 3.4.2.1: Remove the unnecessary transcripts to save memory
ids.ensembl <- ids.ensembl[is.element(ids.ensembl$id_internal_huex, features), ]
#ids.ensembl[is.element(ids.ensembl$id_internal_huex, features), c('id_internal_huex', 'gene_id', 'transcript_id', 'exon_id')]
# Part 3.4.2.2: Create a list of gene names that will be used as rowname
get_probe_info <- function(probeId) {
return(ids.ensembl[ids.ensembl$id_internal_huex == probeid, ])
}
# Part 3.4.3: Insert the diagnosis factor in the dataframe
data.multinomial <- rbind(data.multinomial, diagnosis)
data.multinomial <- as.data.frame(t(data.multinomial))
data.multinomial$diagnosis <- factor(data.multinomial$diagnosis, ordered = FALSE)
# Part 3.4.4: Choose the index on which to choose as training
index.multinomial <- createDataPartition(data.multinomial$diagnosis, p = 0.75, list = F)
# Part 3.4.5: To make the training better, perform upsampling
trainset.multinomial <- data.multinomial[index.multinomial, ]
trainset.multinomial <- upSample(trainset.multinomial[, names(trainset.multinomial) %ni% c("diagnosis")], trainset.multinomial$diagnosis, yname = "diagnosis")
# Part 3.4.6: Correct the factors in testing
testset.multinomial <- data.multinomial[-index.multinomial, ]
testset.multinomial$diagnosis <- factor(testset.multinomial$diagnosis, ordered = FALSE)
# Step 3.4.7: Export
write.csv(data.multinomial, paste(datadir, "../Export/Chosen Dataset.csv", sep = ""), row.names = TRUE)
write.csv(ids.ensembl, paste(datadir, "../Export/Chosen Dataset Ensembl.csv", sep = ""), row.names = TRUE)
# Part 4.3.2.1: Perform tuning for SVM and Random Forest
perform_learning("SVM", trainset.multinomial[, features.selected], testset.multinomial[, features.selected], tune = TRUE)
features
features.selected[features.selected %ni% colnames(trainset.multinomial)]
exprs(data.pp)[features, ]
rownames(exprs(data.pp)[features, ])
rownames(exprs(data.pp)[c("3337042", "3556148"), ])
colnames(data.multinomial[c("3337042", "3556148"), ])
colnames(data.multinomial[,c("3337042", "3556148")])
colnames(data.multinomial)
data.multinomial[, "3337042"]
exprs(data.pp)["3337042", ]
features %in% c("3337042")
features.pca
# Step 3.3: Combine the features from Gene Filtering and PCA
features <- unique(append(features.gf, features.pca))
features %in% c("3337042")
# Step 3.3.1: Look for perfect collinearity
data.features <- as.matrix(exprs(data.pp)[features, ])
show_perfect_collinearity(data.features)
# Step 3.3.2: Since there is no perfect collinearity, proceed
data.features <- as.matrix(exprs(data.pp)[features, ])
data.features <- rbind(data.features, diagnosis.binom)
data.features <- as.data.frame(t(data.features))
model.features <- lm(diagnosis.binom ~ ., data = data.features)
# Part 3.3.3: Get only the factors with no to moderate collinearity (VIF <= 5)
features <- names(vif(model.features)[vif(model.features) <= 5])
features <- gsub("`", "", features, fixed = T)
remove(data.features, model.features)
# Part 3.3.4: Put to HTML the names of the features
atab <- aafTableAnn(features.pca, "pd.huex.1.0.st.v2", aaf.handler()[c(1:3,8:9,11:13)])
saveHTML(atab, file=paste(datadir, "../Export/GF + PCA Probe Names.html", sep = ""))
# Part 3.2.14: Create a correlation matrix across each features
features.corr <- rcorr(as.matrix(t(exprs(data.pp)[features, ])))
corrplot(features.corr$r)
# Step 3.2.15: create Venn diagram and display all sets
ggvenn(list('Gene Filter' = features.gf,
'PCA' = features.pca
),
digits = 2
)
# Part 3.4: Splitting dataset
options(scipen=999)  # prevents printing scientific notations.
set.seed(100)
# Part 3.4.1: Get only the chosen features
data.multinomial <- as.matrix(exprs(data.pp)[features, ])
# Part 3.4.2: Replace the features into their transcript ID
# Part 3.4.2.1: Remove the unnecessary transcripts to save memory
ids.ensembl <- ids.ensembl[is.element(ids.ensembl$id_internal_huex, features), ]
#ids.ensembl[is.element(ids.ensembl$id_internal_huex, features), c('id_internal_huex', 'gene_id', 'transcript_id', 'exon_id')]
# Part 3.4.2.2: Create a list of gene names that will be used as rowname
get_probe_info <- function(probeId) {
return(ids.ensembl[ids.ensembl$id_internal_huex == probeid, ])
}
# Part 3.4.3: Insert the diagnosis factor in the dataframe
data.multinomial <- rbind(data.multinomial, diagnosis)
data.multinomial <- as.data.frame(t(data.multinomial))
data.multinomial$diagnosis <- factor(data.multinomial$diagnosis, ordered = FALSE)
# Part 3.4.4: Choose the index on which to choose as training
index.multinomial <- createDataPartition(data.multinomial$diagnosis, p = 0.75, list = F)
# Part 3.4.5: To make the training better, perform upsampling
trainset.multinomial <- data.multinomial[index.multinomial, ]
trainset.multinomial <- upSample(trainset.multinomial[, names(trainset.multinomial) %ni% c("diagnosis")], trainset.multinomial$diagnosis, yname = "diagnosis")
# Part 3.4.6: Correct the factors in testing
testset.multinomial <- data.multinomial[-index.multinomial, ]
testset.multinomial$diagnosis <- factor(testset.multinomial$diagnosis, ordered = FALSE)
# Step 3.4.7: Export
write.csv(data.multinomial, paste(datadir, "../Export/Chosen Dataset.csv", sep = ""), row.names = TRUE)
write.csv(ids.ensembl, paste(datadir, "../Export/Chosen Dataset Ensembl.csv", sep = ""), row.names = TRUE)
save.image("E:/jmcco/OneDrive - University of the Philippines/School/AY 2022-2023/2nd Sem/HI 299 Research Methods in Health Informatics/HI 299 Project/DLPFC-Gene-Expression/Multinomial/.RData")
# Part 4.3: Perform ML
# Part 4.3.1: Gene Filtering Dataset
features.selected <- c(features.gf, "diagnosis")
# Part 4.3.1.1: Perform tuning for SVM and Random Forest
perform_learning("SVM", trainset.multinomial[, features.selected], testset.multinomial[, features.selected], tune = TRUE)
perform_learning("RF", trainset.multinomial[, features.selected], testset.multinomial[, features.selected], tune = TRUE)
# Part 4.3.1.2: Perform analysis
# Part 4.3.1.2.1: Do ensemble of all learning methods
learn.gf.auto <- perform_learning("auto", trainset.multinomial[, features.selected], testset.multinomial[, features.selected])
# Part 4.3.1.2.2: Naive Bayes
learn.gf.nb <- perform_learning("NB", trainset.multinomial[, features.selected], testset.multinomial[, features.selected])
BiocManager::install(
c("Metrics"),
#force = TRUE,
dependencies = TRUE,
lib = package_loc
)
library(MASS, lib.loc = package_loc); library(Metrics, lib.loc = package_loc);
learn.gf.nb
View(learn.gf.nb)
View(learn.gf.nb)
learn.gf.nb$pred
roc(trainset.multinomial[, features.selected], learn.gf.nb$pred)
roc(trainset.multinomial[, features.selected]$diagnosis, learn.gf.nb$pred)
trainset.multinomial[, features.selected]$diagnosis
learn.gf.nb$pred
auc(trainset.multinomial[, features.selected]$diagnosis, learn.gf.nb$pred)
help(predit)
help(predict)
# Part 4.2: Create a function for each ML
perform_learning <- function(method, trainset, testset,
svm.kernel = NULL,
svm.cost = NULL,
rf.ntree = NULL,
rf.mtry = NULL,
export.filename = NULL,
tune = FALSE) {
if (method == "NB") {
# Part 4.1: Naive Bayes
set.seed(100)
model.nb <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "naive_bayes",
trControl = trainControl(method='cv', number=10)
)
pred.model.nb <- predict(model.nb, newdata = testset[, colnames(trainset) != "diagnosis"])
confMatrix.model.nb <- confusionMatrix(pred.model.nb, testset$diagnosis)
var.model.nb <- varImp(model.nb, useModel = TRUE, nonpara = TRUE, scale = TRUE)
print(roc(trainset$diagnosis, predict(model.nb, newdata = testset[, colnames(trainset) != "diagnosis"], type = "response")))
return(list(model = model.nb, pred = pred.model.nb, confMatrix = confMatrix.model.nb, var = var.model.nb))
} else if (method == "KNN") {
# Part 4.2: K Nearest Neighbors
set.seed(100)
trControl.knn <- trainControl(method='repeatedcv', number = 3, allowParallel = TRUE)
trainset.preprocessed <- preProcess(trainset[, colnames(trainset) != "diagnosis"])
model.knn <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "knn",
trControl = trControl.knn,
tuneLength = 20
)
pred.model.knn <- predict(model.knn, newdata = testset)
confMatrix.model.knn <- confusionMatrix(pred.model.knn, testset$diagnosis)
var.model.knn <- varImp(model.knn, useModel = TRUE, nonpara = TRUE, scale = TRUE)
return(list(model = model.knn, pred = pred.model.knn, confMatrix = confMatrix.model.knn, var = var.model.knn))
} else if (method == "DT") {
# Part 4.3: Decision Tree
# Part 4.3.1: Using rpart
model.dt <- rpart(formula = diagnosis ~ .,
data = trainset,
method = "class",
control = rpart.control(minsplit=2, minbucket = 1, cp = 0.001)
)
var.model.dt<- varImp(model.dt, useModel = TRUE, nonpara = TRUE, scale = TRUE)
rpart.plot(model.dt)
pdf(export.filename)
prp(model.dt, extra=104)
dev.off()
# Part 4.3.2: Using train
## 10-fold CV
## repeated ten times
trControl.dt <- trainControl(
method = "repeatedcv",
number = 5,
repeats = 10)
model.dt <- train(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
method = "rpart2",
trControl = trControl.dt
)
pred.model.dt <- predict(model.dt, newdata = testset)
confMatrix.model.dt <- confusionMatrix(pred.model.dt, testset$diagnosis)
return(list(model = model.dt, pred = pred.model.dt, confMatrix = confMatrix.model.dt, var = var.model.dt))
} else if (method == "SVM") {
# Part 4.4: SVM
# For SVM and random forest, cut the dataset to 10% of the dataset to make processing quicker
#trainset.cut <- trainset[sample(x = 1:nrow(trainset), size = nrow(trainset) * .10, replace = TRUE), colnames(trainset)]
#trainset.cut <- upSample(x = trainset.cut[, colnames(trainset.cut) %ni% "ADDEPEV3"], yname = "ADDEPEV3", y = trainset.cut$ADDEPEV3)
if (tune) {
kernels <- c("rbfdot", "polydot", "tanhdot", "vanilladot", "laplacedot", "besseldot", "anovadot", "splinedot")
costs <- c(0.001, 0.01, 0.1, 1, 5, 10, 100)
} else {
kernels <- c(svm.kernel)
costs <- c(svm.cost)
}
for (kernel in kernels) {
for (cost in costs) {
model.svm <- rminer::fit(diagnosis ~ .,
data = trainset,
model = "svm",
kernel = kernel,
kpar = "automatic",
C = cost,
task = "class"
)
pred.model.svm <- predict(model.svm, newdata = testset)
confMatrix.model.svm <- confusionMatrix(pred.model.svm, testset$diagnosis)
if (tune && confMatrix.model.svm$overall['AccuracyPValue'] < 0.05) {
print(paste(kernel," @ ", cost))
print(confMatrix.model.svm)
}
var.model.svm <- Importance(model.svm, data = trainset)
}
}
if (!tune) {
return(list(model = model.nb, pred = pred.model.nb, confMatrix = confMatrix.model.nb, var = var.model.nb))
}
} else if (method == "LOG") {
model.logit <- multinom(diagnosis ~ .,
data = trainset)
pred.model.logit <- predict(model.logit, newdata = testset[, colnames(testset) != "diagnosis"], type = "class")
confMatrix.model.logit <- confusionMatrix(pred.model.logit, testset$diagnosis)
var.model.logit <- varImp(model.logit, useModel = TRUE, nonpara = TRUE, scale = TRUE)
summary(model.logit)
View(cbind("coeff" = coef(model.logit), "odds ratio" = (exp(coef(model.logit)) - 1) * 100)) # Odds ratio
return(list(model = model.logit, pred = pred.model.logit, confMatrix = confMatrix.model.logit, var = var.model.logit))
} else if (method == "DA") {
# Part 4.6: Discriminant Analysis
model.lda <- lda(diagnosis ~ .,
data = trainset,
)
pred.model.lda <- predict(model.lda, newdata = testset)
confMatrix.model.lda <- confusionMatrix(pred.model.lda$class, testset$diagnosis)
#var.model.lda <- varImp(model.lda, useModel = TRUE, nonpara = TRUE, scale = TRUE)
#return(list(model = model.lda, pred = pred.model.lda, confMatrix = confMatrix.model.lda, var = var.model.lda))
return(list(model = model.lda, pred = pred.model.lda, confMatrix = confMatrix.model.lda))
} else if (method == "RF") {
# Part 4.7: Random Forest
set.seed(100)
if (tune) {
mtries <- sort.int(sample(ncol(trainset)-1, 5))
ntrees <- c(201, 501, 1501, 2501, 3501)
} else {
mtries <- c(rf.mtry)
ntrees <- c(rf.ntree)
}
for(ntree in ntrees) {
for(mtry in mtries) {
model.rf <- randomForest(x = trainset[, colnames(trainset) != "diagnosis"],
y = trainset$diagnosis,
ntree = ntree,
mtry = mtry
)
pred.model.rf <- predict(model.rf, newdata = testset)
confMatrix.model.rf <- confusionMatrix(pred.model.rf, testset$diagnosis)
if (tune && confMatrix.model.rf$overall['AccuracyPValue'] < 0.05) {
print(paste(ntree," and ", mtry))
print(confMatrix.model.rf)
}
var.model.rf <- varImp(model.rf, useModel = TRUE, nonpara = TRUE, scale = TRUE)
}
}
if (!tune) {
return(list(model = model.rf, pred = pred.model.rf, confMatrix = confMatrix.model.rf, var = var.model.rf))
}
} else {
model.auto <- rminer::fit(diagnosis ~ .,
data = trainset,
model = "auto",
fdebug = TRUE,
search = list(
search = mparheuristic(
model = c("naive","ctree","cv.glmnet","rpart","kknn","ksvm","lssvm","mlp","mlpe", "randomForest","lda","multinom", "naiveBayes","xgboost"),
task = "class",
inputs = ncol(trainset)-1
),
smethod = "auto",
metric = "AUC",
convex = 0
)
)
pred.model.auto <- predict(model.auto, testset)
var.model.auto <- Importance(model.auto, data = trainset, method = "DSA")
# show leaderboard:
cat("Models  by rank:", model.auto@mpar$LB$model, "\n")
cat("Validation values:", round(model.auto@mpar$LB$eval,4), "\n")
cat("Best model:", model.auto@model, "\n")
cat("AUC", "=", round(mmetric(testset$diagnosis, pred.model.auto, metric="AUC"),2), "\n")
return(list(model = model.auto, pred = pred.model.auto, confMatrix = c(), var = var.model.auto))
}
}
# Part 4.3.2.2.2: Naive Bayes
learn.pca.nb <- perform_learning("NB", trainset.multinomial[, features.selected], testset.multinomial[, features.selected])
roc(trainset.multinomial[, features.selected]$diagnosis, predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial[, features.selected]) != "diagnosis"], type = "response"))
predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial[, features.selected]) != "diagnosis"], type = "response")
predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial[, features.selected]) != "diagnosis"])
roc(trainset.multinomial[, features.selected]$diagnosis, predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial[, features.selected]) != "diagnosis"]))
multiclass.roc(trainset.multinomial[, features.selected]$diagnosis, predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial[, features.selected]) != "diagnosis"]))
multiclass.roc(as.factor(trainset.multinomial[, features.selected]$diagnosis), predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial[, features.selected]) != "diagnosis"]))
pred.model.nb
pred.model.nb$class
predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"], probability = TRUE)
a <- predict(model.nb, newdata = testset.multinomial[, colnames(trainset.multinomial) != "diagnosis"], probability = TRUE)
a
